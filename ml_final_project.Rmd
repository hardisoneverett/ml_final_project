---
title: "final_project"
author: "Hardison Everett"
date: "3/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, cache.lazy = FALSE, echo = TRUE,
                      warning = FALSE, message = FALSE)
```

For this project we were asked to build a machine learning algorithm to classify how well 6 participants performed an exercise activity.  The data to be evaluated was generated by accelerometers placed on different body parts of the participants. 

To begin with, we will read in the data using the code below.

```{r read_data}
library(readr)

model_data <- read.csv(file = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
                     header = TRUE, sep = ",")
validation <- read.csv(file = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
                    header = TRUE, sep = ",")
```

The `model_data` will be used to build and initially test the algorith.  The `validation` data is the data we are asked to predict for the project.

After initially viewing `model_data` and `validation`, it becomes apparent many of the columns consist primarily of NAs.  The code below checks each columns percent NA and sorts descending. Additionally we determine the list of NA columns from the `validation` set contains all of the NA columns.
``` {r NAs}
## Checking columns for NAs
        ##model_data
sort(colSums(is.na(model_data))/nrow(model_data), decreasing = TRUE)
        ##validation
sort(colSums(is.na(validation))/nrow(validation), decreasing = TRUE)

## Creating variable to sort NAs from the model_data
emptycol_mod<-colSums(is.na(model_data))/nrow(model_data) > 0.9

## Creating variable to sort NAs from the validation data
emptycol_val<-colSums(is.na(validation)) == nrow(validation)

## Checking if emptycol_val contains all NA columns
length(emptycol_mod[emptycol_mod] %in% emptycol_val[emptycol_val])
```

The `validation` data has 100 columns consisting of only NAs.  Since these columns will not contribute to prediction they will be removed from `model_data`.  Additionally, the first seven columns are not included in the model since these column contain time and user information.
```{r clean_data}
train_data <- (model_data[!emptycol])
train_data <- train_data[,-c(1:7)]
```

Next, the `train_data` columns will now be checked for variance.
```{r near_zero_values}
library(caret)
nearZeroVar(train_data)
```

The remaining columns appear to have at least some variance.  Next we move on to building the model.  Since this is classification problem, random forest with cross validation will be used.  To begin with, we need to partition the `model_data` into a training set (`training`) and test set (`testing`).  We also change the `classe` variable to type factor. Additionally, we create the folds for cross validation.  In this case, we will be using 5 folds. 
```{r partition_data}
library(tidymodels)

set.seed(1234)
model_split <- initial_split(train_data)
training <- training(model_split)
training$classe<-as.factor(training$classe)
testing <- testing(model_split)

set.seed(1234)
training_folds<-vfold_cv(training, v = 5)
```

The code below will provide us with a template of the code needed to build the model.  In this case, we will be using a ranger implementation of random forest.
```{r training, echo=FALSE}
library(usemodels)
library(ranger)
use_ranger(classe ~ . ,training)
```
Most of the code below will be auto generated by the previous code.  However, we need to change `resamples` in `tune_grid` to our cross validation folds `training_folds`.  We also set `grid` to 10.
```{r }
ranger_recipe <- 
  recipe(formula = classe ~ ., data = training) 

ranger_spec <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger") 

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 

set.seed(20829)
ranger_tune <-
  tune_grid(ranger_workflow, 
            resamples = training_folds, 
            grid = 10)
```
```{r results}
show_best(ranger_tune, metric ="accuracy", n = 5 )
autoplot(ranger_tune)
```
